{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Self Avoiding Walks in an (m,n) grid from (0, 0) to (m,n):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def take_step(current_position, allowed_moves, marker_with_border):\n",
    "    # Returns the matrix indexs of the allowed next steps \n",
    "   \n",
    "    possiblepos = current_position + allowed_moves\n",
    "    # Calculates the 4 possible positions the walker could move to next\n",
    "    \n",
    "    available_bool = np.array([marker_with_border[row[1]][row[0]] == 0  for row in possiblepos])\n",
    "    # Checks if each of the possible positions are empty (cells have 100 in them if part of the previous path or edge)\n",
    "    # and creates an array (faster than list in testing) of booleans if it is available or not.\n",
    "    \n",
    "    return possiblepos[available_bool] # Returns the viable next steps\n",
    "\n",
    "def main(m,n):\n",
    "    # Returns the path of a self avoiding random walk from (0, 0) to (m, n) as a 1d array\n",
    "    \n",
    "    sizex = m + 1\n",
    "    sizey = n +1\n",
    "    # The size of the array has to account for the zeroth x/y rows\n",
    "    \n",
    "    top_pos = np.array([sizex, sizey])\n",
    "    # Creates the array of the final position the walk is aiming to get to  \n",
    "\n",
    "    path = np.zeros((sizex*sizey + 1, 2))\n",
    "    # Makes an array for the maximum length of a walk i.e. a walk that visits all of the available coordinates\n",
    "    # + 1 so that there is always at least 1 row of [-1, -1] at the end to index an cut off - kind of janky\n",
    "    # See path_cut_off in Path Analyser.\n",
    "    \n",
    "    current_position = np.array([1,1])\n",
    "    # Starting position is (1, 1) not (0, 0) to account for the edge\n",
    "    \n",
    "    path[0] = current_position\n",
    "    # Sets the first position in the path to (1, 1) \n",
    "    \n",
    "    allowed_moves = np.array(([1,0],[0,1],[-1,0],[0,-1]), dtype=int)\n",
    "    # The 4 directions that a random walker can go to from its current position\n",
    "    \n",
    "    marker = np.zeros((sizey, sizex),dtype=int)\n",
    "    # Makes an array on which the walker walks on. Cells will be set to 100 to keep track of where the \n",
    "    # walker has previously been.\n",
    "\n",
    "    marker_with_border = np.pad(marker, 1,'constant',constant_values=100)\n",
    "    # Creates an edge of 100 around the original marker array\n",
    "    # This is to stop the take_step trying to index a matrix position outside of the array \n",
    "    # The initial current_position is set to (1, 1) to account for this shift and 1 is subtrated\n",
    "    # from all of the values in the path at the end to counteract this \n",
    "    \n",
    "    marker_with_border[current_position[1]][current_position[0]] = 100\n",
    "    # Sets the initial position to 100 to stop the walker going back to it\n",
    "    \n",
    "    current_step = 1\n",
    "    # To keep track of the next place in the path array to put a value (i.e. the first zero - useful to keep in mind for backtrack)\n",
    "    \n",
    "    while np.array_equal(current_position, top_pos) == False:\n",
    "        # Keeps going until it reaches (m, n)\n",
    "        \n",
    "        candidates = take_step(current_position, allowed_moves, marker_with_border)\n",
    "        # Calls take_step to get back an array of the valid next moves\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "        # Checks if the walker is stuck\n",
    "        \n",
    "                while len(candidates) == 0:\n",
    "                # Until the walker has a valid move\n",
    "                \n",
    "                    current_step -= 1 \n",
    "                    # Goes back in the path array index by 1 i.e. the last non-zero value\n",
    "                    # This is the matrix coordinates the walker currently is at\n",
    "                    \n",
    "                    path[current_step] = np.array([0,0])\n",
    "                    # Erases the current position of the walker from the path - just in case the new path that leads to (m, n) is shorter than the amount of steps currently taken \n",
    "                    \n",
    "                    current_position = path[current_step-1].astype(int)\n",
    "                    # The new current_position of the walker needs to be the position before the walker got stuck\n",
    "                    # As stated above, current_step points to the first zero so this is located 1 index before the \n",
    "                    # current step\n",
    "                    \n",
    "                    candidates = take_step(current_position, allowed_moves, marker_with_border)\n",
    "                    # Calls take_step to get back an array of the valid next moves - to see if there are any now\n",
    "    \n",
    "        random_step = np.random.randint(0,len(candidates))\n",
    "        # Makes a random index out of the available candidates array\n",
    "        \n",
    "        current_position = candidates[random_step]\n",
    "        # Indexes the candidates array to get a random next move\n",
    "\n",
    "        path[current_step] = current_position\n",
    "        # Adds the new position of the walker to the path \n",
    "        \n",
    "        marker_with_border[current_position[1]][current_position[0]] = 100\n",
    "        # Marks that the walker has been to its current position\n",
    "        \n",
    "        current_step +=1        \n",
    "        \n",
    "    path -=1\n",
    "    # Subtracts 1 from all of the elements in the path to account for the marker edge\n",
    "    \n",
    "    path = path.astype(int)\n",
    "    # Makes sure all the elements are ints - for data reasons\n",
    "    \n",
    "    return np.ndarray.flatten(path) # Flattens path to 1d so that it can be compared to find uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Singular: - To call the main function once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "####### Change to specify dimensions of matrix\n",
    "m = 9\n",
    "n= 3\n",
    "#######\n",
    "\n",
    "####### Change to specify amount of simulations\n",
    "amount_of_runs = 4000000\n",
    "#######\n",
    "\n",
    "paths = Parallel(n_jobs=12)(delayed(main)(m,n) for x in range(amount_of_runs))\n",
    "# Parallel splits up the calls of main to different cores until a list of length amount_of_runs has been made\n",
    "# n_jobs= for the amount of cpu core to utilise -1 for all available  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875000000\n"
     ]
    }
   ],
   "source": [
    "fileObj = open(str(m)+','+str(n)+'.txt', 'rb')\n",
    "# Opens the serialised file for reading for the particular matrix\n",
    "\n",
    "old_uniques = pickle.load(fileObj)\n",
    "# Loads the first item in the serialised file - unique paths\n",
    "\n",
    "total_simulations = pickle.load(fileObj)\n",
    "# Loads the second item in the serialised file - total amount of simulations\n",
    "\n",
    "paths = np.vstack((paths, old_uniques))\n",
    "# Adds the new paths generated to the list of known unique paths so that the amount of unqiue paths  \n",
    "\n",
    "total_simulations = total_simulations + amount_of_runs\n",
    "# Updates the total amount of simulations run\n",
    "\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open(str(m)+','+str(n)+'.txt', 'wb')  \n",
    "# Opens the serialised file for writing for the particular matrix\n",
    "\n",
    "unique_rows = np.unique(paths, axis=0)\n",
    "# Finds the new amount of unique paths\n",
    "\n",
    "pickle.dump(unique_rows,fileObj)\n",
    "# Writes all of the unique paths to the serialised file\n",
    "\n",
    "print(total_simulations)\n",
    "pickle.dump(total_simulations,fileObj)\n",
    "# Writes the total amount of simulations to the serialised file\n",
    "\n",
    "\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For NEW Files - If there isn't a file already set up yet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print ('New File')\n",
    "total_simulations = amount_of_runs\n",
    "\n",
    "fileObj = open(str(m)+','+str(n)+'.txt', 'wb')  \n",
    "unique_rows = np.unique(paths, axis=0)\n",
    "\n",
    "\n",
    "pickle.dump(unique_rows,fileObj)\n",
    "print(total_simulations)\n",
    "pickle.dump(total_simulations,fileObj)\n",
    "\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Multiple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_job(m,n):\n",
    "    # Just the code for the single run but as a function so that it can be called multiple times\n",
    "    \n",
    "    amount_of_runs = 5*10**6\n",
    "    paths = Parallel(n_jobs=12)(delayed(main)(m,n) for x in range(amount_of_runs))\n",
    "    \n",
    "    \n",
    "    print('Opening')\n",
    "    fileObj = open(str(m)+','+str(n)+'.txt', 'rb')\n",
    "    \n",
    "    old_uniques = pickle.load(fileObj)\n",
    "    total_simulations = pickle.load(fileObj)\n",
    "    paths = np.vstack((paths, old_uniques))\n",
    "    \n",
    "    total_simulations = total_simulations + amount_of_runs\n",
    "    fileObj.close()\n",
    "\n",
    "    fileObj = open(str(m)+','+str(n)+'.txt', 'wb')  \n",
    "\n",
    "    unique_rows = np.unique(paths, axis=0)\n",
    "\n",
    "\n",
    "    pickle.dump(unique_rows,fileObj)\n",
    "    print(total_simulations)\n",
    "    pickle.dump(total_simulations,fileObj)\n",
    "\n",
    "    fileObj.close()\n",
    "    print('Closing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening\n",
      "1330000000\n",
      "Closing\n",
      "Opening\n",
      "1335000000\n",
      "Closing\n",
      "Opening\n",
      "1340000000\n",
      "Closing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2f76f340586e>\u001b[0m in \u001b[0;36mmain_job\u001b[1;34m(m, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mamount_of_runs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamount_of_runs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda 2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda 2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda 2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda 2\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda 2\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "listofmat = np.array(([9,3],[9,3],[9,3],[9,3],[9,3],[9,3]))\n",
    "# Specify which arrays and in what order the program does\n",
    "\n",
    "for i in listofmat:\n",
    "    main_job(i[0],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
